python pyspark queries - 

pyspark \
--master yarn \
--deploy-mode client \
--num-executors 15 \
--executor-memory 20g \
--driver-memory 5g \
--executor-cores 3 \
--conf spark.files.ignoreMissingFiles=True \
--conf spark.shuffle.service.enabled=false \
--conf spark.driver.maxResultSize=16g \
--jars '/opt/mapr/sqoop/sqoop-1.4.7/lib/jtds-1.3.1.jar' \
--conf spark.sql.debug.maxToStringFields=-1 \
--conf spark.shuffle.service.enabled=false \
--conf spark.sql.analyzer.failAmbiguousSelfJoin=false \
--conf spark.sql.legacy.charVarcharAsString=true \
--conf spark.sql.hive.convertMetastoreParquet=False \
--conf spark.unsafe.sorter.spill.read.ahead.enabled=false \
--conf spark.executor.memoryOverhead=4096M \
--conf spark.sql.parquet.writeLegacyFormat=true \
--conf spark.hadoop.hive.exec.dynamic.partition=true \
--conf spark.hadoop.hive.exec.dynamic.partition.mode=nonstrict \
--conf spark.port.maxRetries=100 \
--queue opsictm_q1.models_sq1





